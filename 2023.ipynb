{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! .venv\\Scripts\\pip install darts\n",
    "# ! .venv\\Scripts\\pip install dask dask[distributed]\n",
    "# ! .venv\\Scripts\\pip install bokeh dask[dataframe] pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 22:15:54,163 - distributed.nanny - ERROR - Failed to start process\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 452, in instantiate\n",
      "    result = await self.process.start()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 758, in start\n",
      "    msg = await self._wait_until_connected(uid)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 904, in _wait_until_connected\n",
      "    raise msg[\"exception\"]\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 955, in run\n",
      "    worker = worker_factory()\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\worker.py\", line 715, in __init__\n",
      "    ServerNode.__init__(\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "TypeError: Server.__init__() got an unexpected keyword argument 'memory'\n",
      "2024-10-21 22:15:54,183 - distributed.nanny - ERROR - Failed to start process\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 452, in instantiate\n",
      "    result = await self.process.start()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 758, in start\n",
      "    msg = await self._wait_until_connected(uid)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 904, in _wait_until_connected\n",
      "    raise msg[\"exception\"]\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 955, in run\n",
      "    worker = worker_factory()\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\worker.py\", line 715, in __init__\n",
      "    ServerNode.__init__(\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "TypeError: Server.__init__() got an unexpected keyword argument 'memory'\n",
      "2024-10-21 22:15:54,185 - distributed.nanny - ERROR - Failed to start process\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 452, in instantiate\n",
      "    result = await self.process.start()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 758, in start\n",
      "    msg = await self._wait_until_connected(uid)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 904, in _wait_until_connected\n",
      "    raise msg[\"exception\"]\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 955, in run\n",
      "    worker = worker_factory()\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\worker.py\", line 715, in __init__\n",
      "    ServerNode.__init__(\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "TypeError: Server.__init__() got an unexpected keyword argument 'memory'\n",
      "2024-10-21 22:15:54,189 - distributed.nanny - ERROR - Failed to start process\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 452, in instantiate\n",
      "    result = await self.process.start()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 758, in start\n",
      "    msg = await self._wait_until_connected(uid)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 904, in _wait_until_connected\n",
      "    raise msg[\"exception\"]\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py\", line 955, in run\n",
      "    worker = worker_factory()\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\worker.py\", line 715, in __init__\n",
      "    ServerNode.__init__(\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "TypeError: Server.__init__() got an unexpected keyword argument 'memory'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Nanny failed to start.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\core.py:525\u001b[0m, in \u001b[0;36mServer.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m wait_for(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_unsafe(), timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\utils.py:1921\u001b[0m, in \u001b[0;36mwait_for\u001b[1;34m(fut, timeout)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[1;32m-> 1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py:369\u001b[0m, in \u001b[0;36mNanny.start_unsafe\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    368\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Start Nanny at: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress)\n\u001b[1;32m--> 369\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate()\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m!=\u001b[39m Status\u001b[38;5;241m.\u001b[39mrunning:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py:452\u001b[0m, in \u001b[0;36mNanny.instantiate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py:758\u001b[0m, in \u001b[0;36mWorkerProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_until_connected(uid)\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;66;03m# NOTE: doesn't wait for process to terminate, just for terminate signal to be sent\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py:904\u001b[0m, in \u001b[0;36mWorkerProcess._wait_until_connected\u001b[1;34m(self, uid)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m msg:\n\u001b[1;32m--> 904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\nanny.py:955\u001b[0m, in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     worker \u001b[38;5;241m=\u001b[39m worker_factory()\n\u001b[0;32m    956\u001b[0m     failure_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\worker.py:715\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m()\u001b[0m\n\u001b[0;32m    702\u001b[0m stream_handlers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose,\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancel-compute\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_remote_stimulus(CancelComputeEvent),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove-worker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_remove_worker,\n\u001b[0;32m    713\u001b[0m }\n\u001b[1;32m--> 715\u001b[0m ServerNode\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    717\u001b[0m     handlers\u001b[38;5;241m=\u001b[39mhandlers,\n\u001b[0;32m    718\u001b[0m     stream_handlers\u001b[38;5;241m=\u001b[39mstream_handlers,\n\u001b[0;32m    719\u001b[0m     connection_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_args,\n\u001b[0;32m    720\u001b[0m     local_directory\u001b[38;5;241m=\u001b[39mlocal_directory,\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preload:\n",
      "\u001b[1;31mTypeError\u001b[0m: Server.__init__() got an unexpected keyword argument 'memory'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the client\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2GB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This starts the Dask scheduler and worker processes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\client.py:1224\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[0m\n\u001b[0;32m   1221\u001b[0m preload_argv \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed.client.preload-argv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreloads \u001b[38;5;241m=\u001b[39m preloading\u001b[38;5;241m.\u001b[39mprocess_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[1;32m-> 1224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1225\u001b[0m Client\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecreate_tasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\client.py:1426\u001b[0m, in \u001b[0;36mClient.start\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_started \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1426\u001b[0m     \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\utils.py:440\u001b[0m, in \u001b[0;36msync\u001b[1;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m         wait(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\utils.py:414\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    412\u001b[0m         awaitable \u001b[38;5;241m=\u001b[39m wait_for(awaitable, timeout)\n\u001b[0;32m    413\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(awaitable)\n\u001b[1;32m--> 414\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m    416\u001b[0m     error \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\tornado\\gen.py:766\u001b[0m, in \u001b[0;36mRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    768\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[0;32m    769\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\client.py:1491\u001b[0m, in \u001b[0;36mClient._start\u001b[1;34m(self, timeout, **kwargs)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeploy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalCluster\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m LocalCluster(\n\u001b[0;32m   1492\u001b[0m         loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop,\n\u001b[0;32m   1493\u001b[0m         asynchronous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asynchronous,\n\u001b[0;32m   1494\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_startup_kwargs,\n\u001b[0;32m   1495\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m     address \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster\u001b[38;5;241m.\u001b[39mscheduler_address\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_semaphore \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mSemaphore(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\deploy\\spec.py:420\u001b[0m, in \u001b[0;36mSpecCluster.__await__.<locals>._\u001b[1;34m()\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start()\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correct_state()\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[0;32m    423\u001b[0m         [\n\u001b[0;32m    424\u001b[0m             asyncio\u001b[38;5;241m.\u001b[39mcreate_task(_wrap_awaitable(w))\n\u001b[0;32m    425\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    426\u001b[0m         ]\n\u001b[0;32m    427\u001b[0m     )  \u001b[38;5;66;03m# maybe there are more\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\deploy\\spec.py:390\u001b[0m, in \u001b[0;36mSpecCluster._correct_state_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     w\u001b[38;5;241m.\u001b[39m_cluster \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# Collect exceptions from failed workers. This must happen after all\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# *other* workers have finished initialising, so that we can have a\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# proper teardown.\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mworker_futs)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:694\u001b[0m, in \u001b[0;36m_wrap_awaitable\u001b[1;34m(awaitable)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;129m@types\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_awaitable\u001b[39m(awaitable):\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for asyncio.ensure_future().\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m    Wraps awaitable (an object with __await__) into a coroutine\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;124;03m    that will later be wrapped in a Task by ensure_future().\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01myield from\u001b[39;00m awaitable\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__await__\u001b[39m())\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\distributed\\core.py:533\u001b[0m, in \u001b[0;36mServer.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m _close_on_failure(exc)\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed to start.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39minit:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m Status\u001b[38;5;241m.\u001b[39mrunning\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Nanny failed to start."
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Initialize the client\n",
    "client = Client(n_workers=4, memory=\"2GB\")  # This starts the Dask scheduler and worker processes\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_parquet('TRAIN_Reco_2021_2022_2023.parquet.gzip').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionTime    datetime64[ns, Europe/Berlin]\n",
       "ID                             string[pyarrow]\n",
       "high                                   float16\n",
       "low                                    float16\n",
       "close                                  float16\n",
       "volume                                 float16\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ExecutionTime'] = dd.to_datetime(df['ExecutionTime'])\n",
    "numerical_columns = ['high', 'low', 'close', 'volume']\n",
    "df[numerical_columns] = df[numerical_columns].astype('float16')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = '2022-01-01'\n",
    "train_end_date = '2023-06-30'\n",
    "\n",
    "val_start_date = '2023-07-01'\n",
    "val_end_date = '2023-12-31'  # Adjust if you have data beyond 2023\n",
    "\n",
    "# Step 4: Split the data into training and validation sets\n",
    "train_df = df[(df['ExecutionTime'] >= train_start_date) & (df['ExecutionTime'] <= train_end_date)]\n",
    "val_df = df[(df['ExecutionTime'] >= val_start_date) & (df['ExecutionTime'] <= val_end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dask_expr.expr.Scalar: expr=(DropDuplicates(frame=(Filter(frame=Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e)))), predicate=Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e))))['ExecutionTime'] >= 2022-01-01 & Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e))))['ExecutionTime'] <= 2023-06-30))['ID'], split_every=False)).count(), dtype=int64> <dask_expr.expr.Scalar: expr=(DropDuplicates(frame=(Filter(frame=Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e)))), predicate=Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e))))['ExecutionTime'] >= 2023-07-01 & Assign(frame=Assign(frame=ResetIndex(frame=ReadParquetFSSpec(60b046e))))['ExecutionTime'] <= 2023-12-31))['ID'], split_every=False)).count(), dtype=int64>\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"ID\"].nunique(), val_df[\"ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 1073741824 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask_expr\\_collection.py:481\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    480\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\base.py:372\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask_expr\\_expr.py:3778\u001b[0m, in \u001b[0;36mFused._execute_task\u001b[1;34m(graph, name, *deps)\u001b[0m\n\u001b[0;32m   3776\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(deps):\n\u001b[0;32m   3777\u001b[0m     graph[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m dep\n\u001b[1;32m-> 3778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:97\u001b[0m, in \u001b[0;36mParquetFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(part, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     95\u001b[0m     part \u001b[38;5;241m=\u001b[39m [part]\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_parquet_part\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Temporary workaround for HLG serialization bug\u001b[39;49;00m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# (see: https://github.com/dask/dask/issues/8581)\u001b[39;49;00m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:647\u001b[0m, in \u001b[0;36mread_parquet_part\u001b[1;34m(fs, engine, meta, part, columns, index, kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[1;32m--> 647\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    657\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:648\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[0;32m    647\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 648\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (rg, kw) \u001b[38;5;129;01min\u001b[39;00m part\n\u001b[0;32m    656\u001b[0m     ]\n\u001b[0;32m    657\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:641\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_partition\u001b[1;34m(cls, fs, pieces, columns, index, dtype_backend, categories, partitions, filters, schema, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m     row_group \u001b[38;5;241m=\u001b[39m [row_group]\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# Read in arrow table and convert to pandas\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_frag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_read:\n\u001b[0;32m    653\u001b[0m     tables\u001b[38;5;241m.\u001b[39mappend(arrow_table)\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:1774\u001b[0m, in \u001b[0;36mArrowDatasetEngine._read_table\u001b[1;34m(cls, path_or_frag, fs, row_groups, columns, schema, filters, partitions, partition_keys, **kwargs)\u001b[0m\n\u001b[0;32m   1767\u001b[0m     arrow_table \u001b[38;5;241m=\u001b[39m frag\u001b[38;5;241m.\u001b[39mto_table(\n\u001b[0;32m   1768\u001b[0m         use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1769\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1770\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcols,\n\u001b[0;32m   1771\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m_filters_to_expression(filters) \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1772\u001b[0m     )\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1774\u001b[0m     arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43m_read_table_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_frag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;66;03m# For pyarrow.dataset api, if we did not read directly from\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# fragments, we need to add the partitioned columns here.\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partitions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partitions, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:264\u001b[0m, in \u001b[0;36m_read_table_from_path\u001b[1;34m(path, fs, row_groups, columns, schema, filters, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_input_files(\n\u001b[0;32m    258\u001b[0m     [path],\n\u001b[0;32m    259\u001b[0m     fs\u001b[38;5;241m=\u001b[39mfs,\n\u001b[0;32m    260\u001b[0m     precache_options\u001b[38;5;241m=\u001b[39mprecache_options,\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_file_options,\n\u001b[0;32m    262\u001b[0m )[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m fil:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row_groups \u001b[38;5;241m==\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParquetFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mread_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pq\u001b[38;5;241m.\u001b[39mParquetFile(fil, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpre_buffer)\u001b[38;5;241m.\u001b[39mread_row_groups(\n\u001b[0;32m    272\u001b[0m             row_groups,\n\u001b[0;32m    273\u001b[0m             columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mread_kwargs,\n\u001b[0;32m    277\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pyarrow\\parquet\\core.py:623\u001b[0m, in \u001b[0;36mParquetFile.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03mRead a Table from Parquet format.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03manimal: [[\"Flamingo\",\"Parrot\",...,\"Brittle stars\",\"Centipede\"]]\u001b[39;00m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    621\u001b[0m column_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_column_indices(\n\u001b[0;32m    622\u001b[0m     columns, use_pandas_metadata\u001b[38;5;241m=\u001b[39muse_pandas_metadata)\n\u001b[1;32m--> 623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pyarrow\\_parquet.pyx:1704\u001b[0m, in \u001b[0;36mpyarrow._parquet.ParquetReader.read_all\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 1073741824 failed"
     ]
    }
   ],
   "source": [
    "train_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('ExecutionTime', inplace=True)\n",
    "val_df.set_index('ExecutionTime', inplace=True)\n",
    "\n",
    "def create_lag_rolling_features(df):\n",
    "    # Lag features\n",
    "    for column in ['low', 'high', 'close', 'volume']:\n",
    "        for lag in range(1, 11):  # Create 10 lags\n",
    "            df[f'{column}_lag_{lag}'] = df[column].shift(lag)\n",
    "    \n",
    "    # Rolling window features (rolling mean of the last 10 periods)\n",
    "    for column in ['low', 'high', 'close', 'volume']:\n",
    "        df[f'{column}_rolling_mean_10'] = df[column].rolling(window=10).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_14520\\2639633781.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('ID').apply(create_lag_rolling_features)\n",
      "C:\\Users\\a4293604\\AppData\\Local\\Temp\\ipykernel_14520\\2639633781.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  val_df = val_df.groupby('ID').apply(create_lag_rolling_features)\n"
     ]
    }
   ],
   "source": [
    "# Apply the lag and rolling window function to each asset group separately in the training set\n",
    "train_df = train_df.groupby('ID').apply(create_lag_rolling_features)\n",
    "\n",
    "# Apply the lag and rolling window function to each asset group separately in the validation set\n",
    "val_df = val_df.groupby('ID').apply(create_lag_rolling_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values resulting from lagging\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>low_lag_1</th>\n",
       "      <th>low_lag_2</th>\n",
       "      <th>low_lag_3</th>\n",
       "      <th>low_lag_4</th>\n",
       "      <th>low_lag_5</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_lag_5</th>\n",
       "      <th>volume_lag_6</th>\n",
       "      <th>volume_lag_7</th>\n",
       "      <th>volume_lag_8</th>\n",
       "      <th>volume_lag_9</th>\n",
       "      <th>volume_lag_10</th>\n",
       "      <th>low_rolling_mean_10</th>\n",
       "      <th>high_rolling_mean_10</th>\n",
       "      <th>close_rolling_mean_10</th>\n",
       "      <th>volume_rolling_mean_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>ExecutionTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Fri00Q1</th>\n",
       "      <th>2022-01-01 02:30:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:45:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:15:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:30:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID  high  low  close  volume  \\\n",
       "ID      ExecutionTime                                                  \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0   \n",
       "        2022-01-01 02:45:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0   \n",
       "        2022-01-01 03:00:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0   \n",
       "        2022-01-01 03:15:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0   \n",
       "        2022-01-01 03:30:00+01:00  Fri00Q1   0.0  0.0    0.0     0.0   \n",
       "\n",
       "                                   low_lag_1  low_lag_2  low_lag_3  low_lag_4  \\\n",
       "ID      ExecutionTime                                                           \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 02:45:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:00:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:15:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:30:00+01:00        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                                   low_lag_5  ...  volume_lag_5  volume_lag_6  \\\n",
       "ID      ExecutionTime                         ...                               \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 02:45:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:00:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:15:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:30:00+01:00        0.0  ...           0.0           0.0   \n",
       "\n",
       "                                   volume_lag_7  volume_lag_8  volume_lag_9  \\\n",
       "ID      ExecutionTime                                                         \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00           0.0           0.0           0.0   \n",
       "        2022-01-01 02:45:00+01:00           0.0           0.0           0.0   \n",
       "        2022-01-01 03:00:00+01:00           0.0           0.0           0.0   \n",
       "        2022-01-01 03:15:00+01:00           0.0           0.0           0.0   \n",
       "        2022-01-01 03:30:00+01:00           0.0           0.0           0.0   \n",
       "\n",
       "                                   volume_lag_10  low_rolling_mean_10  \\\n",
       "ID      ExecutionTime                                                   \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00            0.0                  0.0   \n",
       "        2022-01-01 02:45:00+01:00            0.0                  0.0   \n",
       "        2022-01-01 03:00:00+01:00            0.0                  0.0   \n",
       "        2022-01-01 03:15:00+01:00            0.0                  0.0   \n",
       "        2022-01-01 03:30:00+01:00            0.0                  0.0   \n",
       "\n",
       "                                   high_rolling_mean_10  \\\n",
       "ID      ExecutionTime                                     \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                   0.0   \n",
       "        2022-01-01 02:45:00+01:00                   0.0   \n",
       "        2022-01-01 03:00:00+01:00                   0.0   \n",
       "        2022-01-01 03:15:00+01:00                   0.0   \n",
       "        2022-01-01 03:30:00+01:00                   0.0   \n",
       "\n",
       "                                   close_rolling_mean_10  \\\n",
       "ID      ExecutionTime                                      \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                    0.0   \n",
       "        2022-01-01 02:45:00+01:00                    0.0   \n",
       "        2022-01-01 03:00:00+01:00                    0.0   \n",
       "        2022-01-01 03:15:00+01:00                    0.0   \n",
       "        2022-01-01 03:30:00+01:00                    0.0   \n",
       "\n",
       "                                   volume_rolling_mean_10  \n",
       "ID      ExecutionTime                                      \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                     0.0  \n",
       "        2022-01-01 02:45:00+01:00                     0.0  \n",
       "        2022-01-01 03:00:00+01:00                     0.0  \n",
       "        2022-01-01 03:15:00+01:00                     0.0  \n",
       "        2022-01-01 03:30:00+01:00                     0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35150304, 49)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11411904, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['high', 'low', 'close', 'volume']\n",
    "\n",
    "# Create copies of the DataFrames\n",
    "train_df_scaled = train_df.copy()\n",
    "val_df_scaled = val_df.copy()\n",
    "\n",
    "# Dictionary to store scalers for each asset\n",
    "scalers = {}\n",
    "\n",
    "# Assets present in training data\n",
    "assets_in_train = train_df_scaled.index.get_level_values('ID').unique()\n",
    "\n",
    "for asset in assets_in_train:\n",
    "    # Training data for this asset\n",
    "    asset_train_data = train_df_scaled.loc[asset, columns_to_scale]\n",
    "    \n",
    "    # Initialize and fit the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_train_values = scaler.fit_transform(asset_train_data)\n",
    "    \n",
    "    # Replace training data with scaled values\n",
    "    train_df_scaled.loc[asset, columns_to_scale] = scaled_train_values\n",
    "    \n",
    "    # Store the scaler\n",
    "    scalers[asset] = scaler\n",
    "    \n",
    "    # Check if the asset exists in validation data\n",
    "    if asset in val_df_scaled.index.get_level_values('ID'):\n",
    "        asset_val_data = val_df_scaled.loc[asset, columns_to_scale]\n",
    "        \n",
    "        # Transform validation data\n",
    "        scaled_val_values = scaler.transform(asset_val_data)\n",
    "        \n",
    "        # Replace validation data with scaled values\n",
    "        val_df_scaled.loc[asset, columns_to_scale] = scaled_val_values\n",
    "    else:\n",
    "        # Asset not in validation data; no action needed\n",
    "        pass\n",
    "\n",
    "# Handle assets present only in validation data\n",
    "assets_in_val = val_df_scaled.index.get_level_values('ID').unique()\n",
    "assets_only_in_val = set(assets_in_val) - set(assets_in_train)\n",
    "\n",
    "for asset in assets_only_in_val:\n",
    "    print(f\"Warning: Asset {asset} is present in validation data but not in training data. Skipping scaling for this asset.\")\n",
    "    # Decide how to handle these assets\n",
    "    # For example, you could drop them:\n",
    "    val_df_scaled = val_df_scaled.drop(asset, level='ID')\n",
    "\n",
    "# # Reset index if necessary\n",
    "# train_df_scaled = train_df_scaled.reset_index()\n",
    "# val_df_scaled = val_df_scaled.reset_index()\n",
    "\n",
    "# Now proceed with your modeling using train_df_scaled and val_df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35150304, 49)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_scaled[\"ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_scaled_df = train_df_scaled\n",
    "new_val_scaled_df = val_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>low_lag_1</th>\n",
       "      <th>low_lag_2</th>\n",
       "      <th>low_lag_3</th>\n",
       "      <th>low_lag_4</th>\n",
       "      <th>low_lag_5</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_lag_6</th>\n",
       "      <th>volume_lag_7</th>\n",
       "      <th>volume_lag_8</th>\n",
       "      <th>volume_lag_9</th>\n",
       "      <th>volume_lag_10</th>\n",
       "      <th>low_rolling_mean_10</th>\n",
       "      <th>high_rolling_mean_10</th>\n",
       "      <th>close_rolling_mean_10</th>\n",
       "      <th>volume_rolling_mean_10</th>\n",
       "      <th>ID_numeric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>ExecutionTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Fri00Q1</th>\n",
       "      <th>2022-01-01 02:30:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:45:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:15:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:30:00+01:00</th>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID  high      low  close  volume  \\\n",
       "ID      ExecutionTime                                                      \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "        2022-01-01 02:45:00+01:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "        2022-01-01 03:00:00+01:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "        2022-01-01 03:15:00+01:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "        2022-01-01 03:30:00+01:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "\n",
       "                                   low_lag_1  low_lag_2  low_lag_3  low_lag_4  \\\n",
       "ID      ExecutionTime                                                           \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 02:45:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:00:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:15:00+01:00        0.0        0.0        0.0        0.0   \n",
       "        2022-01-01 03:30:00+01:00        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                                   low_lag_5  ...  volume_lag_6  volume_lag_7  \\\n",
       "ID      ExecutionTime                         ...                               \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 02:45:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:00:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:15:00+01:00        0.0  ...           0.0           0.0   \n",
       "        2022-01-01 03:30:00+01:00        0.0  ...           0.0           0.0   \n",
       "\n",
       "                                   volume_lag_8  volume_lag_9  volume_lag_10  \\\n",
       "ID      ExecutionTime                                                          \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00           0.0           0.0            0.0   \n",
       "        2022-01-01 02:45:00+01:00           0.0           0.0            0.0   \n",
       "        2022-01-01 03:00:00+01:00           0.0           0.0            0.0   \n",
       "        2022-01-01 03:15:00+01:00           0.0           0.0            0.0   \n",
       "        2022-01-01 03:30:00+01:00           0.0           0.0            0.0   \n",
       "\n",
       "                                   low_rolling_mean_10  high_rolling_mean_10  \\\n",
       "ID      ExecutionTime                                                          \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                  0.0                   0.0   \n",
       "        2022-01-01 02:45:00+01:00                  0.0                   0.0   \n",
       "        2022-01-01 03:00:00+01:00                  0.0                   0.0   \n",
       "        2022-01-01 03:15:00+01:00                  0.0                   0.0   \n",
       "        2022-01-01 03:30:00+01:00                  0.0                   0.0   \n",
       "\n",
       "                                   close_rolling_mean_10  \\\n",
       "ID      ExecutionTime                                      \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                    0.0   \n",
       "        2022-01-01 02:45:00+01:00                    0.0   \n",
       "        2022-01-01 03:00:00+01:00                    0.0   \n",
       "        2022-01-01 03:15:00+01:00                    0.0   \n",
       "        2022-01-01 03:30:00+01:00                    0.0   \n",
       "\n",
       "                                   volume_rolling_mean_10  ID_numeric  \n",
       "ID      ExecutionTime                                                  \n",
       "Fri00Q1 2022-01-01 02:30:00+01:00                     0.0           0  \n",
       "        2022-01-01 02:45:00+01:00                     0.0           0  \n",
       "        2022-01-01 03:00:00+01:00                     0.0           0  \n",
       "        2022-01-01 03:15:00+01:00                     0.0           0  \n",
       "        2022-01-01 03:30:00+01:00                     0.0           0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_scaled_df['ID_numeric'] = new_train_scaled_df['ID'].astype('category').cat.codes\n",
    "new_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'high', 'low', 'close', 'volume', 'low_lag_1', 'low_lag_2',\n",
       "       'low_lag_3', 'low_lag_4', 'low_lag_5', 'low_lag_6', 'low_lag_7',\n",
       "       'low_lag_8', 'low_lag_9', 'low_lag_10', 'high_lag_1', 'high_lag_2',\n",
       "       'high_lag_3', 'high_lag_4', 'high_lag_5', 'high_lag_6', 'high_lag_7',\n",
       "       'high_lag_8', 'high_lag_9', 'high_lag_10', 'close_lag_1', 'close_lag_2',\n",
       "       'close_lag_3', 'close_lag_4', 'close_lag_5', 'close_lag_6',\n",
       "       'close_lag_7', 'close_lag_8', 'close_lag_9', 'close_lag_10',\n",
       "       'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_4',\n",
       "       'volume_lag_5', 'volume_lag_6', 'volume_lag_7', 'volume_lag_8',\n",
       "       'volume_lag_9', 'volume_lag_10', 'low_rolling_mean_10',\n",
       "       'high_rolling_mean_10', 'close_rolling_mean_10',\n",
       "       'volume_rolling_mean_10', 'ID_numeric'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_scaled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone information from the 'ExecutionTime' column\n",
    "# new_train_scaled_df['ExecutionTime'] = pd.to_datetime(new_train_scaled_df['ExecutionTime']).dt.tz_localize(None)\n",
    "# new_train_scaled_df.index = new_train_scaled_df.index.tz_localize(None)\n",
    "\n",
    "# Remove 'ID' from the index, keep 'ExecutionTime' as the index\n",
    "new_train_scaled_df = new_train_scaled_df.reset_index(level='ID', drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ExecutionTime</th>\n",
       "      <th>ID</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>low_lag_1</th>\n",
       "      <th>low_lag_2</th>\n",
       "      <th>low_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_lag_6</th>\n",
       "      <th>volume_lag_7</th>\n",
       "      <th>volume_lag_8</th>\n",
       "      <th>volume_lag_9</th>\n",
       "      <th>volume_lag_10</th>\n",
       "      <th>low_rolling_mean_10</th>\n",
       "      <th>high_rolling_mean_10</th>\n",
       "      <th>close_rolling_mean_10</th>\n",
       "      <th>volume_rolling_mean_10</th>\n",
       "      <th>ID_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01 02:30:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 02:45:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-01 03:15:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-01 03:30:00</td>\n",
       "      <td>Fri00Q1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       ExecutionTime       ID  high      low  close  volume  \\\n",
       "0      0 2022-01-01 02:30:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "1      1 2022-01-01 02:45:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "2      2 2022-01-01 03:00:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "3      3 2022-01-01 03:15:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "4      4 2022-01-01 03:30:00  Fri00Q1   0.0  0.04895    0.0     0.0   \n",
       "\n",
       "   low_lag_1  low_lag_2  low_lag_3  ...  volume_lag_6  volume_lag_7  \\\n",
       "0        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "1        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "2        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "3        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "4        0.0        0.0        0.0  ...           0.0           0.0   \n",
       "\n",
       "   volume_lag_8  volume_lag_9  volume_lag_10  low_rolling_mean_10  \\\n",
       "0           0.0           0.0            0.0                  0.0   \n",
       "1           0.0           0.0            0.0                  0.0   \n",
       "2           0.0           0.0            0.0                  0.0   \n",
       "3           0.0           0.0            0.0                  0.0   \n",
       "4           0.0           0.0            0.0                  0.0   \n",
       "\n",
       "   high_rolling_mean_10  close_rolling_mean_10  volume_rolling_mean_10  \\\n",
       "0                   0.0                    0.0                     0.0   \n",
       "1                   0.0                    0.0                     0.0   \n",
       "2                   0.0                    0.0                     0.0   \n",
       "3                   0.0                    0.0                     0.0   \n",
       "4                   0.0                    0.0                     0.0   \n",
       "\n",
       "   ID_numeric  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_scaled_df = new_train_scaled_df.reset_index()\n",
    "new_train_scaled_df['ExecutionTime'] = pd.to_datetime(new_train_scaled_df['ExecutionTime']).dt.tz_localize(None)\n",
    "\n",
    "new_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.88 GiB for an array with shape (44, 35150304) and data type float16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_train_scaled_df \u001b[38;5;241m=\u001b[39m \u001b[43mnew_train_scaled_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4869\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4866\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   4868\u001b[0m bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m axis_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4869\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4875\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4877\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   4878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.88 GiB for an array with shape (44, 35150304) and data type float16"
     ]
    }
   ],
   "source": [
    "new_train_scaled_df = new_train_scaled_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Delete unused variables\n",
    "# del large_unused_dataframe\n",
    "\n",
    "# Explicitly call garbage collection\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 268. MiB for an array with shape (35150304,) and data type datetime64[ns]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m new_train_scaled_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m target_columns \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecutionTime\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Convert the dataframe into Darts TimeSeries objects\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# TimeSeries for target variables (multivariate time series)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_train_scaled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExecutionTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# TimeSeries for covariates (including lags, rolling means, and ID_numeric)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m covariates \u001b[38;5;241m=\u001b[39m TimeSeries\u001b[38;5;241m.\u001b[39mfrom_dataframe(new_train_scaled_df, time_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecutionTime\u001b[39m\u001b[38;5;124m'\u001b[39m, value_cols\u001b[38;5;241m=\u001b[39mfeature_columns \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\darts\\timeseries.py:745\u001b[0m, in \u001b[0;36mTimeSeries.from_dataframe\u001b[1;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value, static_covariates, hierarchy)\u001b[0m\n\u001b[0;32m    736\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m xa \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[0;32m    739\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mvalues[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[0;32m    740\u001b[0m     dims\u001b[38;5;241m=\u001b[39m(time_index\u001b[38;5;241m.\u001b[39mname,) \u001b[38;5;241m+\u001b[39m DIMS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:],\n\u001b[0;32m    741\u001b[0m     coords\u001b[38;5;241m=\u001b[39m{time_index\u001b[38;5;241m.\u001b[39mname: time_index, DIMS[\u001b[38;5;241m1\u001b[39m]: series_df\u001b[38;5;241m.\u001b[39mcolumns},\n\u001b[0;32m    742\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m{STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},\n\u001b[0;32m    743\u001b[0m )\n\u001b[1;32m--> 745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_xarray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\darts\\timeseries.py:474\u001b[0m, in \u001b[0;36mTimeSeries.from_xarray\u001b[1;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(xa_)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxa_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\darts\\timeseries.py:165\u001b[0m, in \u001b[0;36mTimeSeries.__init__\u001b[1;34m(self, xa, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(xa\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# The following sorting returns a copy, which we are relying on.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# As of xarray 0.18.2, this sorting discards the freq of the index for some reason\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# https://github.com/pydata/xarray/issues/5466\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# We sort only if the time axis is not already sorted (monotonically increasing).\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xa\u001b[38;5;241m.\u001b[39mget_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_dim)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_index, VALID_INDEX_TYPES):\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\darts\\timeseries.py:4763\u001b[0m, in \u001b[0;36mTimeSeries._sort_index\u001b[1;34m(xa, copy)\u001b[0m\n\u001b[0;32m   4758\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sorts an xarray by its time dimension index (only if it is not already monotonically increasing).\"\"\"\u001b[39;00m\n\u001b[0;32m   4759\u001b[0m time_dim \u001b[38;5;241m=\u001b[39m xa\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m   4761\u001b[0m     (xa\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[0;32m   4762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xa\u001b[38;5;241m.\u001b[39mget_index(time_dim)\u001b[38;5;241m.\u001b[39mis_monotonic_increasing\n\u001b[1;32m-> 4763\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mxa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4764\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataarray.py:5126\u001b[0m, in \u001b[0;36mDataArray.sortby\u001b[1;34m(self, variables, ascending)\u001b[0m\n\u001b[0;32m   5124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(variables):\n\u001b[0;32m   5125\u001b[0m     variables \u001b[38;5;241m=\u001b[39m variables(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 5126\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataset.py:8195\u001b[0m, in \u001b[0;36mDataset.sortby\u001b[1;34m(self, variables, ascending)\u001b[0m\n\u001b[0;32m   8193\u001b[0m     variables \u001b[38;5;241m=\u001b[39m variables\n\u001b[0;32m   8194\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, DataArray) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables]\n\u001b[1;32m-> 8195\u001b[0m aligned_vars \u001b[38;5;241m=\u001b[39m \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8196\u001b[0m aligned_self \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf\u001b[39m\u001b[38;5;124m\"\u001b[39m, aligned_vars[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   8197\u001b[0m aligned_other_vars \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mtuple\u001b[39m[DataArray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], aligned_vars[\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\alignment.py:883\u001b[0m, in \u001b[0;36malign\u001b[1;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03mGiven any number of Dataset and/or DataArray objects, returns new\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03mobjects with aligned indexes and dimension sizes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    873\u001b[0m \n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    875\u001b[0m aligner \u001b[38;5;241m=\u001b[39m Aligner(\n\u001b[0;32m    876\u001b[0m     objects,\n\u001b[0;32m    877\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    881\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    882\u001b[0m )\n\u001b[1;32m--> 883\u001b[0m \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligner\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\alignment.py:583\u001b[0m, in \u001b[0;36mAligner.align\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\alignment.py:558\u001b[0m, in \u001b[0;36mAligner.reindex_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex_all\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects_matching_indexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\alignment.py:559\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex_all\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj, matching_indexes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    561\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects_matching_indexes, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    562\u001b[0m         )\n\u001b[0;32m    563\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\alignment.py:547\u001b[0m, in \u001b[0;36mAligner._reindex_one\u001b[1;34m(self, obj, matching_indexes)\u001b[0m\n\u001b[0;32m    544\u001b[0m new_indexes, new_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_indexes_and_vars(obj, matching_indexes)\n\u001b[0;32m    545\u001b[0m dim_pos_indexers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dim_pos_indexers(matching_indexes)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_callback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_pos_indexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataarray.py:1917\u001b[0m, in \u001b[0;36mDataArray._reindex_callback\u001b[1;34m(self, aligner, dim_pos_indexers, variables, indexes, fill_value, exclude_dims, exclude_vars)\u001b[0m\n\u001b[0;32m   1914\u001b[0m         fill_value[_THIS_ARRAY] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m   1916\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_temp_dataset()\n\u001b[1;32m-> 1917\u001b[0m reindexed \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_callback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43maligner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_pos_indexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1927\u001b[0m da \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(reindexed)\n\u001b[0;32m   1928\u001b[0m da\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataset.py:3530\u001b[0m, in \u001b[0;36mDataset._reindex_callback\u001b[1;34m(self, aligner, dim_pos_indexers, variables, indexes, fill_value, exclude_dims, exclude_vars)\u001b[0m\n\u001b[0;32m   3528\u001b[0m         reindexed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overwrite_indexes(new_indexes, new_variables)\n\u001b[0;32m   3529\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3530\u001b[0m         reindexed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3532\u001b[0m     to_reindex \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3533\u001b[0m         k: v\n\u001b[0;32m   3534\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3535\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m variables \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude_vars\n\u001b[0;32m   3536\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataset.py:1371\u001b[0m, in \u001b[0;36mDataset.copy\u001b[1;34m(self, deep, data)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, data: DataVars \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a copy of this dataset.\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m    If `deep=True`, a deep copy is made of each of the component variables.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    pandas.DataFrame.copy\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\dataset.py:1407\u001b[0m, in \u001b[0;36mDataset._copy\u001b[1;34m(self, deep, data, memo)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         variables[k] \u001b[38;5;241m=\u001b[39m index_vars[k]\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1407\u001b[0m         variables[k] \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1409\u001b[0m attrs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs, memo) \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;28;01melse\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs)\n\u001b[0;32m   1410\u001b[0m encoding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1411\u001b[0m     copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding, memo) \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;28;01melse\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding)\n\u001b[0;32m   1412\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\xarray\\core\\variable.py:929\u001b[0m, in \u001b[0;36mVariable._copy\u001b[1;34m(self, deep, data, memo)\u001b[0m\n\u001b[0;32m    926\u001b[0m         ndata \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mMemoryCachedArray(data_old\u001b[38;5;241m.\u001b[39marray)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 929\u001b[0m         ndata \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    932\u001b[0m     ndata \u001b[38;5;241m=\u001b[39m as_compatible_data(data)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:211\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[1;32m--> 211\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:1304\u001b[0m, in \u001b[0;36mIndex.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m    memo, default None\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;124;03m        Standard signature. Unused\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:1286\u001b[0m, in \u001b[0;36mIndex.copy\u001b[1;34m(self, name, deep)\u001b[0m\n\u001b[0;32m   1284\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_names(name\u001b[38;5;241m=\u001b[39mname, deep\u001b[38;5;241m=\u001b[39mdeep)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m-> 1286\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1287\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(new_data, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:2354\u001b[0m, in \u001b[0;36mTimelikeOps.copy\u001b[1;34m(self, order)\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, order: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m-> 2354\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2355\u001b[0m     new_obj\u001b[38;5;241m.\u001b[39m_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_obj\n",
      "File \u001b[1;32marrays.pyx:148\u001b[0m, in \u001b[0;36mpandas._libs.arrays.NDArrayBacked.copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 268. MiB for an array with shape (35150304,) and data type datetime64[ns]"
     ]
    }
   ],
   "source": [
    "target_columns = ['high', 'low', 'close', 'volume']\n",
    "feature_columns = [col for col in new_train_scaled_df.columns if col not in target_columns + ['ID_numeric', 'ExecutionTime']]\n",
    "\n",
    "# Step 2: Convert the dataframe into Darts TimeSeries objects\n",
    "# TimeSeries for target variables (multivariate time series)\n",
    "targets = TimeSeries.from_dataframe(new_train_scaled_df, time_col='ExecutionTime', value_cols=target_columns)\n",
    "\n",
    "# TimeSeries for covariates (including lags, rolling means, and ID_numeric)\n",
    "covariates = TimeSeries.from_dataframe(new_train_scaled_df, time_col='ExecutionTime', value_cols=feature_columns + ['ID_numeric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a4293604\\Documents\\deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train = new_train_scaled_df.drop(['ID', 'ExecutionTime', 'high', 'low', 'close', 'volume'], axis=1)\n",
    "\n",
    "# Targets\n",
    "y_train = new_train_scaled_df[['high', 'low', 'close', 'volume']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    input_chunk_length=15,  # Number of past time steps to use as input\n",
    "    output_chunk_length=10,  # Number of future time steps to predict\n",
    "    model=\"LSTM\",  # You can choose between \"RNN\", \"LSTM\", and \"GRU\"\n",
    "    n_epochs=100,\n",
    "    batch_size=32,\n",
    "    random_state=42\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
